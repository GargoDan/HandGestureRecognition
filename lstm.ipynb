{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('csv_data//train.csv', index_col=0)\n",
    "test = pd.read_csv('csv_data//test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['const'], inplace=True)\n",
    "test.drop(columns=['const'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np = np.zeros((train.num_of_action.nunique(), 30, train.shape[1] - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n"
     ]
    }
   ],
   "source": [
    "X_train_np = np.zeros((314, 30, train.shape[1] - 2))\n",
    "Y_train_np = np.zeros(314)\n",
    "i = 0\n",
    "for action in train.action.unique():\n",
    "    for num in train.num_of_action.unique():\n",
    "        shape_0 = train.loc[(train.num_of_action == num) & (train.action == action)].iloc[:, :-2].shape[0]\n",
    "        if shape_0 != 0:\n",
    "            assert shape_0 == 30, (num, action)\n",
    "            X_train_np[i] = train.loc[(train.num_of_action == num) & (train.action == action)].iloc[:, :-2]\n",
    "            Y_train_np[i] = train.loc[(train.num_of_action == num) & (train.action == action)].iloc[-1, -2]\n",
    "            i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "X_test_np = np.zeros((80, 30, test.shape[1] - 2))\n",
    "Y_test_np = np.zeros(80)\n",
    "i = 0\n",
    "for action in test.action.unique():\n",
    "    for num in test.num_of_action.unique():\n",
    "        shape_0 = test.loc[(test.num_of_action == num) & (test.action == action)].iloc[:, :-2].shape[0]\n",
    "        if shape_0 != 0:\n",
    "            assert shape_0 == 30, (num, action)\n",
    "            X_test_np[i] = test.loc[(test.num_of_action == num) & (test.action == action)].iloc[:, :-2]\n",
    "            Y_test_np[i] = test.loc[(test.num_of_action == num) & (test.action == action)].iloc[-1, -2]\n",
    "            i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "Y_train_np = to_categorical(Y_train_np).astype(int)\n",
    "Y_test_np = to_categorical(Y_test_np).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('csv_data/X_train_np', X_train_np)\n",
    "np.save('csv_data/X_test_np', X_test_np)\n",
    "np.save('csv_data/Y_train_np', Y_train_np)\n",
    "np.save('csv_data/Y_test_np', Y_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30, train.shape[1] - 2)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 946, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 935, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 928, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 846, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 668, in apply_gradients\n        grads_and_vars = self._aggregate_gradients(grads_and_vars)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 484, in _aggregate_gradients\n        return self.gradient_aggregator(grads_and_vars)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\utils.py\", line 33, in all_reduce_sum_gradients\n        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n\n    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11524/936553191.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 946, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 935, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 928, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 846, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 668, in apply_gradients\n        grads_and_vars = self._aggregate_gradients(grads_and_vars)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 484, in _aggregate_gradients\n        return self.gradient_aggregator(grads_and_vars)\n    File \"C:\\Users\\dandy\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\utils.py\", line 33, in all_reduce_sum_gradients\n        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n\n    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_np, Y_train_np, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fccb30966a34eb4c203704ea4419f01615b8311d9095c0bab7b138fa2d01430"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
